import random
import time

nodes = []

weights = [-0.16386173065957768, -0.06784658344236037, -0.015815323304483153, 0.04931585443435075, 0.21707444097326212, -0.04739437939232115, -0.08453594365553717, 0.0256589585553824, 0.08093929654773596, 0.03567919918654876, 0.11637020201885562, 0.10743599578522815, 0.025484987497699264, 0.06651384941645083, 0.19084684310544164, -0.35360148338837905, -0.07952016623935672, -0.11564016435941495, 0.008062028392607466, 0.11405986820030366, 0.010467828651392317, -0.15659878356550952, -0.10055719793328269, 0.16330060278946237, -0.021366206885110678, -0.04428986114198706, 0.12919002595589893, -0.00893905001736348, -0.11979906253039418, 0.06747958221992034, -0.0991454415567083, 0.05247434783190218, 0.14748236609581655, -0.2205217630727757, 0.11678730710739882, 0.08229894658166302, -0.14201499386471034, -0.19418044467493262, -0.04693753192439245, -0.049361917621923226, 0.017224884187002, -0.25433068119883245, -0.051349528691116475, -0.1096456201793887, -0.03396942595842216, -0.12050438511335705, 0.01023465541119957, -0.10027274653187958, -0.2221353931526133, -0.030641653344704357, -0.13944396389415212, -0.15254339122540725, -0.2121285960186016, 0.06376074728604382, -0.23021095496406196, 0.1259653862276986, -0.035353502720726564, -0.17428512302308735, -0.20262908985069675, 0.043964060328538, -0.10790657246753897, -0.20822970099097562, -0.030195401291011056, -0.061131941898761186, -0.062451083913126315, 0.14575450272747112, 0.15828852729168122, 0.10759673164467921, -0.08534121742561666, 0.011234091737418201, 0.05794270864657414, -0.015787178561682307, -0.0994335742704451, 0.0021120056627824107, -0.1560670790143866, -0.10144509598963611, -0.16396481697152548, 0.007875904807413578, -0.15833563934171924, -0.005552177190447637, -0.21185136605809812, -0.0980483054472497, -0.018916310942101507, -0.16909982405663182, 0.027594349165388495, 0.01056002656902121, -0.16680708722924778, 0.04303178249173921, -0.09741469828669477, -0.014729005876693886, -0.06048663533813343, -0.12165754881097471, -0.27798757441137323, -0.232798915772126, -0.25016664620847806, -0.1688035837747834, -0.17491768367145605, -0.19462022921447106, -0.13856345790220984, -0.1157122373553227, 0.16201758993577228, -0.13342697245282648, -0.012637881813270222, 0.01712708570551453, 0.03767302666774462, 0.12196695818313988, 0.040787940901962944, -0.07887312327883766, -0.04430596355763242, -0.21056262475427068, -0.31763719253658773, -0.01710902084863362, -0.2960674165945606, -0.21488134134502948, -0.2465106126023327, -0.047980316768508634, -0.09265354358060167, -0.17067520398317101, -0.12194280795274035, -0.15666089758264623, -0.12709243826376698, -0.44853303870215294, -0.26995155824291855, -0.09403328047385713, -0.12423383063430044, -0.2137961011272132, -0.29886420115717177, -0.18458917348700968, 0.016215728283079277, -0.05685888183216842, -0.06106599511079639, -0.18414288159475892, -0.16440505954795048, -0.06972854954089096, -0.4937187603681126, 0.011392454152934411, -0.23412011097656815, -0.0758056420568643, 0.13384386295017534, -0.008337744353334273, -0.06870815842351023, -0.0046048002484866315, 0.05347864584422513, -0.009842836291415396, -0.009387730958454889, -0.026196947163400593, 0.15359130751876887, 0.20322785005637103, 0.0900408546547379, 0.029966529096036, -0.011677697687433855, -0.0006097786183063868, -0.10289158656829638, -0.11867969127883835, 0.058967697639986376, -0.07393720650873414, -0.0005455597351313054, -0.01073350087898515, -0.063057673455721, 0.3107268289102174, -0.0014140549562830472, -0.17969432353040415, 0.06418010490700374, -0.004615373980685941, 0.1562776477915731, -0.12006359225193683, 0.12822925004373203, -0.10486294818809061, 0.2971663367771392, 0.045128498509610475, 0.510749242134429, 0.19487309109694745, 0.21354545609708706, 0.48911220778947856, -0.01650728419156134, -0.2882229469955366, 0.09395632577643977, 0.15641655810148242, 0.14330511920974648, 0.12780247516766158]

#[0.7962194427262359, 0.8679136356598196, 1.345672324836952, 0.7107690480459323, 0.7189847086695862, 0.09622256967096318, 0.42791886820574265, 1.3031794297969592, -0.3689764222778109, -0.015442874224206926, -0.07920273673900985, -0.5280142372452709, 0.26634206883452877, 0.0032430609155442514, 0.9178467229570844, 0.27951436956422665, -0.1095795548247234, 0.7691664842621744, -0.05031832331869129, -0.0394776140478494, 1.7979141229402131, 0.15856123770819713, -0.00507558315255628, -0.16340426147575965, -0.13016428241044714, 1.1302766810555767, 0.34627340327790507, 0.19997919675180484, -0.14752148848777072, -0.07664769957986546, 1.1436526589066236, 1.0671646637881214, 2.085862676233181, 0.7958645853459808, 1.1764094455209346, 0.7694987035976301, 0.6216995479379452, -0.47481916806923546, 1.0965130062663526, 0.6085135489805698, 0.1294976219828699, 1.3261138308718043, 0.025436346945815484, 0.16156872118296942, 1.3422329659291012, -0.12733273521912192, 0.5491375978619222, 0.5671193258513063, 0.8457940283299448, -0.5229823728114003, 0.8089812643121039, -0.1594870765579088, 0.9752253633852064, 1.0917765985068948, 0.7164631173246411, -0.5991989957415279, 1.084055978859935, 1.2174296697698737, -0.6803578280586566, 0.7087640109568999, 0.7198969783629129, 0.45427395426052347, -0.25444642860661537, 0.7307941507419792, 0.5262033898050019, 0.819429556952168, 0.6301039521548017, 1.1770499763897888, 1.5499290650089628, 1.3647090236245787, 0.5586087823279018, 1.2082936422181374, 1.2953320405889115, 1.3500282047571817, 0.056912961871348006, -0.2638961363604728, 0.2185039117991345, 0.37555002835887186, 0.2851073126949273, 0.06540392283032595, 0.5829592845344722, 2.2360759283395097, 0.2449155642489743, 0.13803978705747413, 0.854719524215686, 0.13471279469880237, 0.5591455507283938, -1.1481894253026923, 0.3539200393378668, 0.4938995045494968, 0.21185921704676913, 0.169414792682728, 0.2914889868413274, -0.6947977228082256, 0.1906634263868198, 0.40041538107418967, 0.1188822883544649, 0.6417426120605517, 0.32147701341618506, 2.4826227875332108, 0.1272732883723633, -0.012603704495031794, 0.3663733928805913, 0.8473542656174747, 1.063344612273713, 0.8654906398679084, 0.8112849873414726, 1.0009288895070596, 1.0590307262275316, 0.25071605042332556, -0.7203910088062605, 0.36565539965631205, 0.5261612162869103, -0.9272305977134786, 1.0303954371541884, 0.10278691223570148, -0.008066049596298216, 0.10585113498922742, 0.16435953578179463, -1.2154315785410013, 0.692649654112871, -0.059815484738408115, 1.3253223903373705, 0.5273584584532695, 0.4285343798307263, 2.1324643575516293, 0.6205121810506705, 0.9588653412639484, 0.9159110256044164, 0.19671139332996326, -0.11127627040439694, 1.1631364458448505, 0.60523898481079, 0.3343835275787304, 1.2816630449419317, -0.13188165037572758, -0.0026406245936370382, 1.1278221961639927, 1.4786204587157044, 1.0094078912430473, 0.8072776374696843, 0.9407892660083346, 1.2091939679322443, 0.7939001728000052, 1.007002448538206, 1.0406663892138723, 1.1665661199242818, 0.41911491230277814, 0.7300162099388413, 0.5074402143773588, 0.785236412526618, 0.658677455126833, 1.2805641330254538, 0.281512927752482, 1.2162029938930778, 1.1768194480466572, 0.8338955386950271, 0.903834475129456, 0.9737794694045684, 1.7734539769575541, 0.840631480326589, 1.030452793529139, 0.6779911409757606, 1.1643529480607535, 1.1424731183150767, 0.7861559555608123, 1.1175347992357827, 0.5812378350183479, 0.4712619346187793, 0.2911856460307302, 0.45970440471282853, -0.04885593600332515, -0.02017399113397975, -0.11131071739237292, 0.7107231503166969, 1.0892071618205381, 0.9110701723766078, 0.6091903101522917, 0.7762570844429182, 0.6603167273420392]
#above set uses ReLU


weights_trial = []
loss_best = 100000000000000
itC = 0
species = 0
data_examples = 50

# 6x6 neural network with a bias node for each layer. Rectified linear function will be used.


len_weights = 6*6*5
#for i in range(0, len_weights):
    #weights.append(0)
    #weights_trial.append(0)

len_nodes = 6*6
for i in range(0,len_nodes):
    nodes.append(0)



def sigmoid(x):
    if(x > 20):
        x = 20
    if(x < -20):
        x = -20
    sigma = (1 / (1 + 2 ** x))
    return sigma
    #if(x > 0):
        #return x
    #else:
        #return 0


def ff(x_in, y_in, weights_in, nodes_in):
    nodes_in[0] = 1
    nodes_in[1] = x_in
    nodes_in[2] = y_in
    nodes_in[3] = 1
    nodes_in[4] = 1
    nodes_in[5] = 1

    for i in range(6,len_nodes):
        if(i % 6 == 0):
            nodes_in[i] = 1
        else:
            nodes_in[i] = 0
            for j in range(0, 6):
                # Add and weight all nodes in previous layer
                node_index = j + (i - i % 6) - 6
                weight_index = (i - 7) * 6 + j
                #print("node " + str(node_index) + " connected by " + str(weight_index) + " to " + str(i))
                nodes_in[i] += nodes_in[node_index] * weights_in[weight_index]
            nodes_in[i] = sigmoid(nodes[i])
    return nodes_in[-1]

#print(ff(1, 1, weights, nodes))

def extract_numbers_from_file(file_path):
    numbers = []
    try:
        with open(file_path, 'r') as file:
            for i, line in enumerate(file):
                if i >= data_examples:  # Process only the first 1000 lines
                    break

                parts = line.split()  # Split the line into parts
                
                # Extract and store the first three numbers
                try:
                    first_three_numbers = [float(parts[j]) for j in range(3)]
                    numbers.append(first_three_numbers)
                except (IndexError, ValueError):
                    print(f"Line {i + 1} is malformed or doesn't contain enough numbers.")

    except FileNotFoundError:
        print(f"File not found: {file_path}")

    return numbers

# Example usage
file_path = 'train_data.txt'  # Replace with your file path
extracted_numbers = extract_numbers_from_file(file_path)
#print(extracted_numbers)


def loss(nodes_in, weights_in):
    sum = 0
    for i in range(0, data_examples):
        x = extracted_numbers[i][0]
        y = extracted_numbers[i][1]
        a = extracted_numbers[i][2]
        a_guess = ff(x, y, weights_in, nodes_in)
        loss = ((a - a_guess) ** 2) / data_examples * 100
        sum += loss

    return sum

#print(loss(nodes, weights))

while True:
    #print(loss(nodes, weights))
    for i in range(0, len_weights):
        weights_trial[i] = weights[i]
    random_mag = 10 ** random.randint(-11, -1)
    for i in range(0, len_weights):
        if(random.uniform(0, 1) < 2 / len_weights):
            weights_trial[i] += random.uniform(-1,1) * random_mag
    
    #print(weights_trial)
    loss_trial = loss(nodes, weights_trial)
    if(loss_trial < loss_best):
        loss_best = loss_trial
        print("\n\n\n\n" + str(weights_trial))
        print("\n\n" + str(loss_best))
        for i in range(0, len_weights):
            weights[i] = weights_trial[i]

        species += 1
    itC += 1





